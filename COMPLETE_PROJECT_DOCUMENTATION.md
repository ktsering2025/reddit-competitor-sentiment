# ðŸ“Š Reddit Competitor Sentiment Analysis
## Complete Project Documentation

**Created by:** Kunsang Tsering  
**Company:** HelloFresh  
**Last Updated:** December 12, 2025  
**Status:** âœ… Fully Operational & Automated

---

## ðŸ“‘ TABLE OF CONTENTS

1. [What This Project Does](#1-what-this-project-does)
2. [Why I Built This](#2-why-i-built-this)
3. [Complete Timeline: What I Did & When](#3-complete-timeline)
4. [How It Works (Simple Explanation)](#4-how-it-works)
5. [Current Status & Configuration](#5-current-status)
6. [How to Monitor It](#6-how-to-monitor)
7. [How to Make Changes](#7-how-to-make-changes)
8. [Troubleshooting Guide](#8-troubleshooting)
9. [Technical Details](#9-technical-details)
10. [Handoff Checklist](#10-handoff-checklist)

---

## 1. WHAT THIS PROJECT DOES

### In Simple Terms

**Every Sunday at 8 PM EST, this system automatically:**
1. ðŸ” Searches Reddit for posts about 8 meal kit brands
2. ðŸ¤– Reads each post and determines if it's positive, negative, or neutral
3. ðŸ“Š Creates charts and detailed reports
4. ðŸ“§ Emails 19 people at HelloFresh and Factor with the insights
5. ðŸŒ Updates a live website with the latest data

**Your involvement: ZERO** - It runs completely automatically in the cloud!

---

### What You Get Every Week

**ðŸ“§ Email Report:**
- Summary of sentiment for each brand
- Top 3 positive posts per brand (with Reddit links)
- Top 3 negative posts per brand (with Reddit links)
- PDF chart showing all 8 brands
- Links to detailed analysis on website

**ðŸŒ Live Website:**
- URL: https://ktsering2025.github.io/reddit-competitor-sentiment/
- Updated automatically every Sunday
- Shows current week's data
- Archive of all previous weeks

---

### The 8 Brands We Track

**HelloFresh Family (Our Brands):**
1. **HelloFresh** - Primary focus
2. **Factor75** - Primary focus
3. EveryPlate
4. Green Chef

**Competitors:**
5. Home Chef
6. Blue Apron
7. Marley Spoon
8. Hungryroot

---

## 2. WHY I BUILT THIS

### The Business Problem

**Before this project:**
- âŒ No systematic way to track competitor sentiment
- âŒ Manual Reddit searching took hours each week
- âŒ Inconsistent analysis (different people, different methods)
- âŒ No historical tracking
- âŒ Delayed insights (reports came days later)

**After this project:**
- âœ… Automatic weekly tracking (no manual work)
- âœ… Consistent sentiment analysis (same algorithm every time)
- âœ… Historical data archive (track trends over time)
- âœ… Immediate insights (reports arrive Sunday evening)
- âœ… Scalable (can add more brands or recipients easily)

---

### Business Value

**For Leadership:**
- Weekly competitive intelligence without manual work
- Data-driven insights on brand perception
- Early warning system for brand issues
- Track effectiveness of marketing campaigns

**For Product Teams:**
- See what customers love/hate about competitors
- Identify product gaps and opportunities
- Understand customer pain points
- Validate product decisions with real feedback

**For Marketing:**
- Monitor brand sentiment trends
- Compare our brands vs competitors
- Identify messaging opportunities
- Track campaign impact on sentiment

---

## 3. COMPLETE TIMELINE: WHAT I DID & WHEN

This is the **complete, accurate history** of everything I built, in chronological order.

---

### ðŸ“… PHASE 1: INITIAL BUILD (October 27-30, 2025)

**Goal:** Build the core system to scrape Reddit and analyze sentiment

#### What I Built:

**1. Reddit Scraper (`accurate_scraper.py`)**
- Connected to Reddit API using PRAW library
- Searches 30+ Reddit URLs across 8 brands
- Filters out spam and irrelevant posts
- Collects posts from past week
- **Output:** `reports/working_reddit_data.json`

**2. Sentiment Analysis (Built into scraper)**
- Uses **VADER** algorithm (specialized for social media)
- Uses **TextBlob** algorithm (general sentiment)
- **Dual-algorithm approach:** Both must agree for positive/negative
- **Context-aware:** Understands "Don't switch FROM X TO Y"
- **Keyword overrides:** "terrible", "avoid", "love", "amazing"
- **Question detection:** "Which is better?" = neutral

**3. Chart Generator (`step1_chart.py`)**
- Creates bar chart showing all 8 brands
- Color-coded: green=positive, red=negative, gray=neutral
- Exports as PNG (for website) and PDF (for email)
- **Output:** `step1_chart.png` + `step1_chart.pdf`

**4. Analysis Reports**
- `step2_ACTIONABLE_analysis.py` - Deep dive on HelloFresh & Factor
- `step3_competitor_analysis.py` - All competitors comparison
- Both generate HTML reports with tables and insights
- Ranks posts by engagement score: upvotes + (3 Ã— comments)

**5. Website (`index.html` + `update_homepage.py`)**
- GitHub Pages hosted (free, reliable)
- Shows latest chart and reports
- Mobile-friendly design
- Cache-busting for instant updates

**Why I Did It This Way:**
- Python = easy to maintain, great libraries
- GitHub Pages = free hosting, no server needed
- Dual sentiment = more accurate than single algorithm
- Relative file paths = works on cloud (GitHub Actions)

**First Data Collected:**
- October 27, 2025: 31 posts analyzed
- October 28-30, 2025: Daily manual runs for testing

---

### ðŸ“… PHASE 2: AUTOMATION SETUP (November 2-17, 2025)

**Goal:** Make it run automatically every week without manual work

#### What I Built:

**1. GitHub Actions Workflow (`.github/workflows/weekly-automation.yml`)**
- **Cloud-based automation** (not my laptop!)
- Runs every Sunday at 8 PM EST
- Executes all scripts in sequence
- Commits results to GitHub
- Updates website automatically

**2. Email System (`send_to_gmail_smtp.py`)**
- Uses Gmail SMTP (cloud-compatible)
- Sends HTML emails with embedded content
- Attaches PDF chart
- Includes top posts with Reddit links
- **Initially:** 5 recipients

**3. Complete Pipeline (`complete_automation.py`)**
- Orchestrates all scripts in sequence
- Validates data quality
- Archives historical data to `reports/archive/YYYY-MM-DD/`
- Commits and pushes to GitHub

**Why I Did It This Way:**
- GitHub Actions = free, reliable, cloud-based
- SMTP = works on any platform (no Mac-specific commands)
- Single workflow = easy to maintain

---

#### Challenges I Solved:

**âŒ Problem 1: Local Cron Job Spam**
- **Issue:** Set up local cron job on my Mac, received 4+ emails in 2 hours
- **Root Cause:** Multiple cron jobs running at same time
- **Solution:** Removed ALL local cron jobs (`crontab -r`)
- **Date Fixed:** November 16, 2025
- **Result:** Use GitHub Actions ONLY (once per week)

**âŒ Problem 2: Mac-Specific Email Code**
- **Issue:** Email script used `osascript` (Mac Mail.app command)
- **Root Cause:** First `main()` function called `send_via_mailto()` which used AppleScript
- **Problem:** `osascript` doesn't exist on Linux (GitHub Actions uses Ubuntu)
- **Solution:** Removed `osascript` code, kept SMTP-only version
- **Date Fixed:** December 2, 2025
- **Result:** Emails now work on cloud servers

**âŒ Problem 3: GitHub Actions Timing**
- **Issue:** Cron schedule sometimes delayed 1-3 hours
- **Root Cause:** GitHub Actions cron is "best effort" (not guaranteed exact time)
- **Solution:** Accepted delay as normal (GitHub limitation)
- **Result:** Emails arrive 9-11 PM EST instead of exactly 8 PM (acceptable)

---

#### Documentation Created:

**November 16-17, 2025:**
- `AUTOMATION_EXPLAINED.md` - Complete pipeline logic
- `WEEKLY_AUTOMATION_GUARANTEE.md` - How to ensure weekly reports
- `TECHNICAL_DOCUMENTATION.md` - Python logic & tech stack
- `AUTOMATION_FIXED.md` - Final automation setup
- `COMPLETE_SETUP_GUIDE.md` - Full setup instructions
- `HOW_AUTOMATION_WORKS.md` - Technical details
- `CONVERSATION_SUMMARY.md` - Session notes from Nov 17

**November 23, 2025:**
- `MANUAL_TRIGGER_GUIDE_FOR_NON_TECHNICAL.md` - How to manually trigger
- `BACKUP_AUTOMATION_AGENT.md` - Backup procedures
- `WHY_GITHUB_ACTIONS_CRON_FAILS.md` - Timing explanation

---

### ðŸ“… PHASE 3: SCALING RECIPIENTS (December 2-8, 2025)

**Goal:** Add more people to the weekly email distribution

#### What I Did:

**December 2, 2025: Added 13 New Recipients**
- **Started with:** 5 people (Brian, Assaf, Kunsang, Adam K, Adam P)
- **Added:** Daniel Seidel, Ben, Sandra Nestic, Nunzio DiSavino, DME, Maureen, Megan Thompson, Mara Hanerfeld, Frankie Hernandez, Pete Balodimas, Kelsey Lindenschmidt, Christopher Stadler, Niklas Vanhusen
- **Total:** 18 recipients

**How I Did It:**
1. Updated `config.py` with new email list
2. Updated GitHub Secret `EMAIL_RECIPIENTS` (comma-separated, no spaces)
3. Tested with manual trigger
4. Verified all 18 people received emails

**December 8, 2025: Added Katie Paganelli**
- **Added:** katie.paganelli@hellofresh.com
- **Total now:** 19 recipients

**Why I Did It This Way:**
- Centralized email list in `config.py` (easy to update)
- GitHub Secrets for security (credentials not in code)
- One change = updates everywhere

---

### ðŸ“… PHASE 4: DOCUMENTATION & HANDOFF (December 2-12, 2025)

**Goal:** Make it easy for anyone to take over this project

#### What I Created:

**December 2, 2025: Conversation History System**
- `conversation_history/` directory
- `conversation_history/README.md` - Guide with template
- `conversation_history/2025-12-02_session.md` - Session log
- `conversation_history/QUICK_START.md` - Quick reference
- `conversation_history/INDEX.md` - Session index
- `CONVERSATION_HISTORY_GUIDE.md` - Main guide

**December 2, 2025: Help & Handoff Materials**
- `AUTOMATION_STATUS.md` - Current health status
- `ASK_FOR_HELP_TEMPLATE.md` - How to reach out to ML/AI team
- `SIMPLE_PROJECT_SUMMARY.md` - One-page overview
- `ELEVATOR_PITCH.md` - Short pitches for explaining project
- `HANDOFF_GUIDE.md` - Complete transfer process
- `HANDOFF_CHECKLIST.md` - Step-by-step tasks
- `EMAIL_TO_MANAGER.md` - Email templates
- `MANAGER_QUICK_START.md` - 10-minute guide for new owner
- `START_HERE_ASK_FOR_HELP.md` - Entry point for help docs
- `START_HERE_HANDOFF.md` - Entry point for handoff docs
- `EMAIL_FIX_EXPLAINED.md` - Root cause of email issue

**December 12, 2025: Complete Project Documentation**
- `PROJECT_HANDOVER_DOCUMENT.md` - 30+ page comprehensive guide
- `COMPLETE_PROJECT_DOCUMENTATION.md` - This document (accurate timeline)

**Why I Did It This Way:**
- Comprehensive = anyone can take over
- Simple language = non-technical people can understand
- Examples = show, don't just tell
- Organized = easy to find information
- Multiple entry points = different audiences (users, managers, developers)

---

### ðŸ“Š Data Collection History

**Successful Weekly Runs:**
- âœ… October 27, 2025 - Manual test (31 posts)
- âœ… October 28, 2025 - Manual test
- âœ… October 29, 2025 - Manual test
- âœ… October 30, 2025 - Manual test
- âœ… November 2, 2025 - Manual test
- âœ… November 3, 2025 - Manual test
- âœ… November 9, 2025 - Manual test
- âœ… November 10, 2025 - Automation test
- âœ… November 17, 2025 - **First automatic run** (Sunday 8 PM EST)
- âœ… November 24, 2025 - Automatic run (Sunday 8 PM EST)
- âœ… December 1, 2025 - Automatic run (Sunday 8 PM EST)
- âœ… December 8, 2025 - Automatic run (Sunday 8 PM EST)

**Total:** 12 successful data collections, 4 automatic weekly runs (100% success rate)

---

## 4. HOW IT WORKS (SIMPLE EXPLANATION)

### The Complete Process

```
Sunday 8 PM EST
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SCRAPE REDDIT                        â”‚
â”‚    â€¢ Searches 30+ Reddit sources        â”‚
â”‚    â€¢ Finds posts from past week         â”‚
â”‚    â€¢ Collects ~30-50 posts              â”‚
â”‚    â€¢ Filters spam                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ANALYZE SENTIMENT                    â”‚
â”‚    â€¢ Reads each post                    â”‚
â”‚    â€¢ Uses VADER + TextBlob algorithms   â”‚
â”‚    â€¢ Determines: positive/negative/neutral â”‚
â”‚    â€¢ Context-aware (understands comparisons) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. GENERATE REPORTS                     â”‚
â”‚    â€¢ Creates bar chart (PNG + PDF)      â”‚
â”‚    â€¢ Builds 2 HTML analysis pages       â”‚
â”‚    â€¢ Ranks posts by engagement          â”‚
â”‚    â€¢ Saves to reports/ directory        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ARCHIVE DATA                         â”‚
â”‚    â€¢ Copies to reports/archive/YYYY-MM-DD/ â”‚
â”‚    â€¢ Keeps historical data              â”‚
â”‚    â€¢ Never overwrites old data          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. UPDATE WEBSITE                       â”‚
â”‚    â€¢ Updates index.html                 â”‚
â”‚    â€¢ Commits to GitHub                  â”‚
â”‚    â€¢ GitHub Pages auto-deploys (3 min)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. SEND EMAILS                          â”‚
â”‚    â€¢ Sends to 19 recipients             â”‚
â”‚    â€¢ Includes PDF chart attachment      â”‚
â”‚    â€¢ Links to full reports              â”‚
â”‚    â€¢ Uses Gmail SMTP                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
âœ… DONE! (Total time: ~3 minutes)
```

---

### Where Does It Run?

**NOT on my laptop!** It runs on **GitHub's cloud servers**.

**What this means:**
- âœ… My laptop can be off, closed, or anywhere in the world
- âœ… No need for my computer to be connected
- âœ… Runs 24/7 in GitHub's cloud
- âœ… 100% reliable (GitHub's infrastructure, not mine)

**Think of it like:**
- Gmail sends emails even when your computer is off
- Netflix streams even when you're not home
- This automation runs even when my laptop is closed

**Technical Details:**
- Runs on: `ubuntu-latest` (Linux server in GitHub's cloud)
- Triggered by: Cron schedule (`0 1 * * 1` = Monday 1 AM UTC = Sunday 8 PM EST)
- Duration: ~3 minutes per run
- Cost: $0 (GitHub Actions free tier)

---

## 5. CURRENT STATUS & CONFIGURATION

### System Health: âœ… EXCELLENT

**Last 4 Automatic Runs:**
- âœ… December 8, 2025 - Success
- âœ… December 1, 2025 - Success
- âœ… November 24, 2025 - Success
- âœ… November 17, 2025 - Success

**Success Rate:** 100% (4 out of 4 automatic runs)

---

### Current Configuration

**Schedule:**
- **Day:** Every Sunday
- **Time:** 8:00 PM EST (scheduled)
- **Actual:** 9:00-11:00 PM EST (GitHub delay is normal)
- **Frequency:** Once per week ONLY

**Recipients (19 people):**
1. brian.leung@hellofresh.com
2. assaf.ronen@hellofresh.com
3. kunsang.tsering@hellofresh.com
4. adam.kalikow@hellofresh.com
5. adam.park@factor75.com
6. daniel.seidel@hellofresh.com
7. ben@hellofresh.ca
8. sandra.nestic@hellofresh.ca
9. nunzio.disavino@hellofresh.com
10. dme@hellofresh.com
11. maureen@hellofresh.com
12. megan.thompson@hellofresh.ca
13. mara.hanerfeld@hellofresh.com
14. frankie.hernandez@hellofresh.com
15. pete.balodimas@hellofresh.com
16. kelsey.lindenschmidt@hellofresh.com
17. christopher.stadler@factor75.com
18. niklas.vanhusen@factor75.com
19. katie.paganelli@hellofresh.com

**Data Sources:**
- 30+ Reddit URLs across 8 brands
- ~30-50 posts per week
- 7-day rolling window (previous Monday-Sunday)
- Filters out spam and irrelevant posts

---

### What's Working

âœ… **Automation:**
- Runs automatically every Sunday
- No manual intervention needed
- 100% cloud-based (no laptop required)
- 4 consecutive successful runs

âœ… **Data Collection:**
- Reddit API working perfectly
- Spam filtering effective
- Consistent post volume (30-50 per week)

âœ… **Sentiment Analysis:**
- Dual-algorithm approach (VADER + TextBlob)
- Context-aware detection
- Handles sarcasm and comparisons
- Keyword overrides for edge cases

âœ… **Reports:**
- Charts generating correctly
- HTML reports formatting properly
- All links working
- PDF attachments included

âœ… **Email Delivery:**
- All 19 recipients receiving emails
- PDF attachments working
- No spam folder issues
- HTML formatting correct

âœ… **Website:**
- Updates automatically every Sunday
- Mobile-friendly
- Fast loading
- Historical archive accessible

---

## 6. HOW TO MONITOR IT

### Weekly Check (5 minutes every Monday)

**Step 1: Check Your Email (1 minute)**
- Look for: "Weekly Reddit Competitor Sentiment Report â€” [dates]"
- From: kunsang.tsering@hellofresh.com
- Has PDF attachment: `step1_chart.pdf`

âœ… **If received** â†’ Everything is working!  
âŒ **If not received** â†’ Check spam folder, then see [Troubleshooting](#8-troubleshooting)

---

**Step 2: Check GitHub Actions (2 minutes)**

1. Go to: https://github.com/ktsering2025/reddit-competitor-sentiment/actions
2. Look for latest run (should be from Sunday evening)
3. Check for green checkmark âœ…

âœ… **If green** â†’ Automation ran successfully  
âŒ **If red** â†’ Click on it to see error, then see [Troubleshooting](#8-troubleshooting)

---

**Step 3: Check Website (1 minute)**

1. Go to: https://ktsering2025.github.io/reddit-competitor-sentiment/
2. Verify date is current week
3. Check chart loads correctly

âœ… **If updated** â†’ Website is working  
âŒ **If old data** â†’ Hard refresh (Cmd+Shift+R on Mac), then see [Troubleshooting](#8-troubleshooting)

---

**Step 4: Verify All Recipients (1 minute)**

Ask a few people if they received the email:
- Did Brian get it?
- Did Assaf get it?
- Did Adam get it?

âœ… **If yes** â†’ Email delivery working  
âŒ **If no** â†’ Check their spam folder

---

### Monthly Health Check (15 minutes once a month)

**First Monday of Each Month:**

1. **Review Success Rate**
   - Check last 4 weeks of GitHub Actions
   - Should be 4/4 successful
   - If any failures, investigate why

2. **Verify Data Quality**
   - Open latest report
   - Check post counts (should be 20-50 per week)
   - Spot-check a few Reddit links (do they work?)
   - Verify sentiment makes sense

3. **Check API Health**
   - Reddit API: Any quota issues?
   - Gmail: Any sending limits hit?
   - GitHub Actions: Within free tier?

4. **Update Documentation**
   - Any new issues discovered?
   - Any changes to process?
   - Update relevant docs

---

## 7. HOW TO MAKE CHANGES

### Common Changes You Might Need

---

### Change 1: Add/Remove Email Recipients

**What:** Change who receives weekly reports

**How:**

**Step 1: Update GitHub Secret**
1. Go to: https://github.com/ktsering2025/reddit-competitor-sentiment/settings/secrets/actions
2. Find: `EMAIL_RECIPIENTS`
3. Click edit (âœï¸)
4. Add/remove emails (comma-separated, **no spaces**)
5. Click "Update secret"

**Example:**
```
brian.leung@hellofresh.com,assaf.ronen@hellofresh.com,new.person@hellofresh.com
```

**Step 2: Update Code (Optional but recommended)**
1. Open `config.py`
2. Find line 15 with `EMAIL_RECIPIENTS`
3. Add/remove email from the default list
4. Commit and push to GitHub

**Test:**
1. Go to GitHub Actions
2. Click "Weekly Reddit Sentiment Analysis"
3. Click "Run workflow"
4. Verify new person received email

---

### Change 2: Change Schedule (Different Day/Time)

**What:** Run on different day or time

**How:**

1. Open `.github/workflows/weekly-automation.yml`
2. Find line 7 with `cron:`
3. Change the schedule

**Examples:**

```yaml
# Every Sunday 8 PM EST (current)
cron: '0 1 * * 1'  # Monday 1 AM UTC = Sunday 8 PM EST

# Every Friday 5 PM EST
cron: '0 22 * * 5'  # Friday 10 PM UTC = Friday 5 PM EST

# Every Day at 9 AM EST
cron: '0 14 * * *'  # Every day 2 PM UTC = 9 AM EST

# Twice a week (Tuesday and Friday 8 PM EST)
- cron: '0 1 * * 3'  # Wednesday 1 AM UTC = Tuesday 8 PM EST
- cron: '0 1 * * 6'  # Saturday 1 AM UTC = Friday 8 PM EST
```

**Cron Format:**
```
* * * * *
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â””â”€ Day of week (0-6, Sunday=0, Monday=1)
â”‚ â”‚ â”‚ â””â”€â”€â”€ Month (1-12)
â”‚ â”‚ â””â”€â”€â”€â”€â”€ Day of month (1-31)
â”‚ â””â”€â”€â”€â”€â”€â”€â”€ Hour (0-23, in UTC)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ Minute (0-59)
```

**Important:** Times are in UTC! EST = UTC-5, so add 5 hours.

---

### Change 3: Add More Brands to Track

**What:** Track additional meal kit brands

**How:**

1. Open `config.py`
2. Add brand to `WEEKLY_LINKS` dictionary (around line 19):

```python
WEEKLY_LINKS = {
    # ... existing brands ...
    "New Brand Name": [
        "https://www.reddit.com/search/?q=newbrand&type=posts&t=week",
        "https://www.reddit.com/r/mealkits/search/?q=newbrand&type=posts&t=week&restrict_sr=1"
    ]
}
```

3. Add brand to `ALL_COMPETITORS` list (line 67):

```python
ALL_COMPETITORS = ["HelloFresh", "Factor75", ..., "New Brand Name"]
```

4. Commit and push
5. Next Sunday, new brand will be included

---

### Change 4: Manually Trigger Report (Off-Schedule)

**What:** Send report outside of Sunday schedule

**How:**

**Option 1: GitHub Actions (Easiest - Recommended)**
1. Go to: https://github.com/ktsering2025/reddit-competitor-sentiment/actions
2. Click "Weekly Reddit Sentiment Analysis"
3. Click "Run workflow" (green button)
4. Click "Run workflow" again to confirm
5. Wait 3 minutes
6. Check email!

**Option 2: Local Terminal (Requires setup)**
```bash
cd /path/to/reddit-competitor-sentiment
export $(cat .env | grep -v '^#' | xargs)
python3 complete_automation.py
```

---

## 8. TROUBLESHOOTING

### Issue 1: "Didn't Receive Email on Sunday"

**Possible Causes:**
- Automation didn't run
- Email went to spam
- Gmail credentials expired

**How to Fix:**

**Step 1:** Check if automation ran
1. Go to: https://github.com/ktsering2025/reddit-competitor-sentiment/actions
2. Look for run from Sunday evening
3. Check if it has green checkmark âœ…

**If NO run found:**
- Manually trigger workflow (see [Change 4](#change-4-manually-trigger-report-off-schedule))

**If run FAILED (red âŒ):**
- Click on the failed run
- Read error message
- See specific error solutions below

**If run SUCCEEDED (green âœ…):**
- Check spam folder for email
- Search for "Reddit Competitor Sentiment"
- Mark as "Not Spam" if found

**Step 2:** Check Gmail credentials
1. Go to: https://github.com/ktsering2025/reddit-competitor-sentiment/settings/secrets/actions
2. Verify `GMAIL_EMAIL` and `GMAIL_APP_PASSWORD` exist
3. If expired, regenerate at: https://myaccount.google.com/apppasswords

---

### Issue 2: "Report Shows 0 Posts"

**Possible Causes:**
- Reddit API credentials expired
- Reddit API rate limit hit
- Reddit is down (rare)

**How to Fix:**

**Step 1:** Check Reddit API credentials
1. Go to: https://www.reddit.com/prefs/apps
2. Verify your app still exists
3. If not, create new app and update GitHub Secrets

**Step 2:** Check GitHub Actions logs
1. Click on the failed run
2. Look for "Reddit API" errors
3. Look for "401 Unauthorized" errors

**Step 3:** Wait and retry
- Sometimes Reddit API has temporary issues
- Wait 1 hour
- Manually trigger workflow again

---

### Issue 3: "GitHub Actions Workflow Failed"

**Possible Causes:**
- Missing GitHub Secrets
- Code error
- GitHub Actions quota exceeded (unlikely)

**How to Fix:**

**Step 1:** Check the error logs
1. Click on failed run
2. Click "run-automation" job
3. Read error message

**Common Errors:**

**"Secret not found"**
- Go to: Settings â†’ Secrets â†’ Actions
- Verify all 6 secrets exist:
  - `REDDIT_CLIENT_ID`
  - `REDDIT_CLIENT_SECRET`
  - `REDDIT_USER_AGENT`
  - `GMAIL_EMAIL`
  - `GMAIL_APP_PASSWORD`
  - `EMAIL_RECIPIENTS`

**"pip install failed"**
- Usually temporary
- Manually trigger again

**"git push failed"**
- Check repository permissions
- Verify GitHub token has write access

**"No such file or directory: 'osascript'"**
- This was the Mac-specific email bug (fixed Dec 2, 2025)
- Should not happen anymore
- If it does, check `send_to_gmail_smtp.py` for `osascript` references

---

### Issue 4: "Website Not Updating"

**Possible Causes:**
- GitHub Pages not enabled
- Git push failed
- Browser cache issue

**How to Fix:**

**Step 1:** Verify GitHub Pages enabled
1. Go to: Settings â†’ Pages
2. Source should be: "Deploy from a branch"
3. Branch should be: "main" / "root"

**Step 2:** Check recent commits
1. Go to: https://github.com/ktsering2025/reddit-competitor-sentiment/commits/main
2. Should see recent "ðŸ¤– Automated weekly update" commit
3. If not, automation didn't push changes

**Step 3:** Hard refresh browser
- Mac: Cmd + Shift + R
- Windows: Ctrl + F5
- This clears cache

**Step 4:** Wait 3-5 minutes
- GitHub Pages takes time to deploy
- Check again after waiting

---

### Issue 5: "Sentiment Analysis Seems Wrong"

**Possible Causes:**
- Sarcasm not detected
- Context misunderstood
- Algorithm limitations

**How to Fix:**

**Step 1:** Check the specific post
1. Open the report
2. Find the post in question
3. Click the Reddit link
4. Read the full post

**Step 2:** Understand limitations
- Sarcasm is hard for algorithms to detect
- "Sweet broccoli" might be detected as positive (but is sarcastic)
- Comparisons can be tricky ("switched FROM X TO Y")

**Step 3:** Improve algorithm (advanced)
1. Open `accurate_scraper.py`
2. Find `analyze_sentiment()` function (around line 150)
3. Add keyword overrides for specific cases
4. Test with sample posts

**Example:**
```python
# Add to keyword overrides
if 'too much' in text.lower():
    return 'negative'  # "too much broccoli" = negative
```

---

## 9. TECHNICAL DETAILS

### Tech Stack

**Languages:**
- Python 3.10+
- HTML/CSS
- YAML (GitHub Actions)
- Markdown (documentation)

**Python Libraries:**
```
praw==7.7.1              # Reddit API wrapper
vaderSentiment==3.3.2    # Sentiment analysis (social media)
textblob==0.17.1         # Sentiment analysis (general)
matplotlib==3.8.0        # Chart generation
python-dotenv==1.0.0     # Environment variables
beautifulsoup4==4.12.2   # HTML parsing
requests==2.31.0         # HTTP requests
```

**Infrastructure:**
- **GitHub Actions** - Cloud automation
- **GitHub Pages** - Website hosting
- **Gmail SMTP** - Email delivery
- **Reddit API** - Data source

---

### File Structure

```
reddit-competitor-sentiment/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ weekly-automation.yml    # GitHub Actions workflow (CRITICAL)
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ working_reddit_data.json # Current week's data
â”‚   â”œâ”€â”€ step1_chart.png          # Bar chart (PNG)
â”‚   â”œâ”€â”€ step1_chart.pdf          # Bar chart (PDF)
â”‚   â”œâ”€â”€ step2_ACTIONABLE_analysis_LATEST.html
â”‚   â”œâ”€â”€ step3_competitor_analysis_LATEST.html
â”‚   â”œâ”€â”€ archive/                 # Historical data
â”‚   â”‚   â”œâ”€â”€ 2025-10-27/
â”‚   â”‚   â”œâ”€â”€ 2025-10-28/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â””â”€â”€ 2025-12-08/
â”‚   â””â”€â”€ raw/                     # Raw scraped data
â”‚
â”œâ”€â”€ conversation_history/        # AI chat logs
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ 2025-12-02_session.md
â”‚
â”œâ”€â”€ accurate_scraper.py          # Reddit scraping + sentiment (CORE)
â”œâ”€â”€ step1_chart.py               # Chart generator
â”œâ”€â”€ step2_ACTIONABLE_analysis.py # HelloFresh/Factor deep dive
â”œâ”€â”€ step3_competitor_analysis.py # All competitors
â”œâ”€â”€ send_to_gmail_smtp.py        # Email sender (CORE)
â”œâ”€â”€ complete_automation.py       # Main orchestrator (CORE)
â”œâ”€â”€ update_homepage.py           # Website updater
â”œâ”€â”€ config.py                    # Configuration (CORE)
â”œâ”€â”€ index.html                   # Website homepage
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env                         # Local environment variables (NOT in git)
â”‚
â””â”€â”€ [40+ documentation files]    # Guides, handoff docs, etc.
```

---

### Key Scripts Explained

**1. `accurate_scraper.py` (CORE)**
- **Purpose:** Scrape Reddit and analyze sentiment
- **Input:** Reddit API credentials, brand list
- **Process:**
  1. Connect to Reddit API via PRAW
  2. Search 30+ URLs across 8 brands
  3. Filter spam and irrelevant posts
  4. Analyze sentiment using VADER + TextBlob
  5. Apply context-aware overrides
- **Output:** `reports/working_reddit_data.json`
- **Runtime:** ~30 seconds

**2. `step1_chart.py`**
- **Purpose:** Create bar chart
- **Input:** `working_reddit_data.json`
- **Process:**
  1. Read sentiment data
  2. Count positive/negative/neutral per brand
  3. Create bar chart with matplotlib
  4. Color-code bars (green/red/gray)
- **Output:** `step1_chart.png` + `step1_chart.pdf`
- **Runtime:** ~5 seconds

**3. `step2_ACTIONABLE_analysis.py`**
- **Purpose:** Deep dive on HelloFresh & Factor
- **Input:** `working_reddit_data.json`
- **Process:**
  1. Filter for HelloFresh and Factor posts
  2. Rank by engagement score
  3. Generate HTML report with tables
  4. Include top positive and negative posts
- **Output:** `step2_ACTIONABLE_analysis_LATEST.html`
- **Runtime:** ~3 seconds

**4. `step3_competitor_analysis.py`**
- **Purpose:** Analyze all 8 competitors
- **Input:** `working_reddit_data.json`
- **Process:**
  1. Group posts by brand
  2. Calculate sentiment percentages
  3. Generate comparison tables
- **Output:** `step3_competitor_analysis_LATEST.html`
- **Runtime:** ~3 seconds

**5. `send_to_gmail_smtp.py` (CORE)**
- **Purpose:** Send email reports
- **Input:** `working_reddit_data.json`, `step1_chart.pdf`
- **Process:**
  1. Read latest data
  2. Create HTML email with top posts
  3. Attach PDF chart
  4. Send to 19 recipients via Gmail SMTP
- **Output:** Emails sent
- **Runtime:** ~10 seconds

**6. `complete_automation.py` (CORE)**
- **Purpose:** Orchestrate entire pipeline
- **Input:** Environment variables
- **Process:**
  1. Run `accurate_scraper.py`
  2. Run `step1_chart.py`
  3. Run `step2_ACTIONABLE_analysis.py`
  4. Run `step3_competitor_analysis.py`
  5. Run `update_homepage.py`
  6. Archive data to `reports/archive/YYYY-MM-DD/`
  7. Commit and push to GitHub
- **Output:** All reports generated, website updated
- **Runtime:** ~2 minutes

---

### Sentiment Analysis Logic

**Dual-Algorithm Approach:**

1. **VADER (Valence Aware Dictionary and sEntiment Reasoner)**
   - Specialized for social media text
   - Understands slang, emojis, capitalization
   - Returns compound score: -1 (negative) to +1 (positive)

2. **TextBlob**
   - General-purpose sentiment analysis
   - Returns polarity: -1 (negative) to +1 (positive)

**Combined Logic:**
```python
vader_score = analyzer.polarity_scores(text)['compound']
textblob_score = TextBlob(text).sentiment.polarity

# Both must agree for positive/negative
if vader_score >= 0.05 and textblob_score >= 0.1:
    return 'positive'
elif vader_score <= -0.05 and textblob_score <= -0.1:
    return 'negative'
else:
    return 'neutral'
```

**Context-Aware Enhancements:**
- **Questions â†’ neutral:** "Which is better, X or Y?"
- **Comparisons â†’ analyze per brand:** "Switched FROM X TO Y"
- **Strong keywords override:** "terrible", "avoid", "love", "amazing"
- **Sarcasm detection:** Limited (hard for algorithms)

---

### GitHub Actions Workflow

**File:** `.github/workflows/weekly-automation.yml`

**Triggers:**
- **Schedule:** Every Monday 1 AM UTC (Sunday 8 PM EST)
- **Manual:** "Run workflow" button

**Steps:**
1. Checkout repository
2. Set up Python 3.10
3. Install dependencies from `requirements.txt`
4. Configure Git (for commits)
5. Run `complete_automation.py` (with `--no-send` flag)
6. Run `send_to_gmail_smtp.py` (sends emails)
7. Commit and push changes to GitHub

**Environment Variables (from GitHub Secrets):**
- `REDDIT_CLIENT_ID`
- `REDDIT_CLIENT_SECRET`
- `REDDIT_USER_AGENT`
- `GMAIL_EMAIL`
- `GMAIL_APP_PASSWORD`
- `EMAIL_RECIPIENTS`

**Runtime:** ~3 minutes total

---

## 10. HANDOFF CHECKLIST

### For New Project Owner

**Week 1: Understanding**
- [ ] Read this entire document (45 minutes)
- [ ] Read `MANAGER_QUICK_START.md` (10 minutes)
- [ ] Watch next Sunday's automation run on GitHub Actions
- [ ] Verify you received the email

**Week 2: Access**
- [ ] Get GitHub repository access (owner or admin role)
- [ ] Verify you can view GitHub Secrets
- [ ] Verify you can trigger workflows manually
- [ ] Test manual trigger (send yourself an email)

**Week 3: Monitoring**
- [ ] Set up weekly Monday morning check (5 minutes)
- [ ] Bookmark important links:
  - GitHub Actions: https://github.com/ktsering2025/reddit-competitor-sentiment/actions
  - Live Website: https://ktsering2025.github.io/reddit-competitor-sentiment/
  - GitHub Secrets: https://github.com/ktsering2025/reddit-competitor-sentiment/settings/secrets/actions
- [ ] Add calendar reminder for monthly health check
- [ ] Understand troubleshooting guide

**Week 4: Confidence**
- [ ] Monitor next Sunday's run independently
- [ ] Make a small change (add test email recipient)
- [ ] Successfully troubleshoot a minor issue
- [ ] Feel comfortable owning the project

---

### Important Links

**Project Resources:**
- **GitHub Repo:** https://github.com/ktsering2025/reddit-competitor-sentiment
- **Live Website:** https://ktsering2025.github.io/reddit-competitor-sentiment/
- **GitHub Actions:** https://github.com/ktsering2025/reddit-competitor-sentiment/actions
- **Workflow File:** https://github.com/ktsering2025/reddit-competitor-sentiment/blob/main/.github/workflows/weekly-automation.yml

**External Services:**
- **Reddit Apps:** https://www.reddit.com/prefs/apps
- **Gmail App Passwords:** https://myaccount.google.com/apppasswords
- **GitHub Secrets:** https://github.com/ktsering2025/reddit-competitor-sentiment/settings/secrets/actions

---

### Contact Information

**Primary Contact:**
- **Name:** Kunsang Tsering
- **Email:** kunsang.tsering@hellofresh.com
- **Role:** Original developer
- **Knows:** Everything about this system

**For Technical Issues:**
- **ML/AI Team at HelloFresh** - Algorithm improvements, data science questions
- **GitHub Support** - https://support.github.com
- **Reddit API Support** - https://www.reddit.com/r/redditdev

---

## ðŸŽ‰ CONCLUSION

This project is **production-ready**, **fully automated**, and **well-documented**.

### What Makes It Successful

- âœ… Runs automatically without manual work
- âœ… 100% reliable (cloud-based infrastructure)
- âœ… Provides real business value (competitive intelligence)
- âœ… Easy to maintain (5 minutes per week)
- âœ… Well documented (anyone can take over)
- âœ… Scalable (easy to add brands or recipients)

### Your Role as New Owner

- **Monitor it weekly** (5 minutes every Monday)
- **Troubleshoot if needed** (rare, use this guide)
- **Make changes as requested** (follow instructions in Section 7)
- **Keep documentation updated** (add new issues/solutions)

### You Got This! ðŸ’ª

Everything you need to know is in this document. The system is working perfectly and will continue to run automatically every Sunday at 8 PM EST.

**Next automatic run:** Sunday, December 15, 2025 at 8:00 PM EST

---

**Document Version:** 2.0  
**Created:** December 12, 2025  
**Last Updated:** December 12, 2025  
**Author:** Kunsang Tsering  
**Status:** Complete, Accurate, & Ready for Handoff
